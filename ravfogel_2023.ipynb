{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6df5ca1-b90a-4bd3-a59e-26e3ac738923",
   "metadata": {},
   "source": [
    "# Description-based text similarity\n",
    "\n",
    "Notebook that summarises work from the above paper by Ravfogel et al.\n",
    "\n",
    "09 06 24\n",
    "\n",
    "Recreating some results from the following paper: \n",
    "\n",
    "- https://arxiv.org/pdf/2305.12517\n",
    "- https://github.com/shauli-ravfogel/descriptions\n",
    "- https://huggingface.co/biu-nlp/abstract-sim-sentence\n",
    "\n",
    "Idea:\n",
    "- Text similarity often unsufficient for the task of retrieving information based on an abstract description\n",
    "- This paper demonstrates the use of embeddings that have been trained so that they retrieve examples that match a given description.\n",
    "- A nice demonstration of the use of ChatGPT for generating training data to solve an NLP problem.\n",
    "\n",
    "Data sources:\n",
    "- English Wikipedia\n",
    "  \n",
    "Approach:\n",
    "- Extract sentences from Wikipedia\n",
    "- Take a subset of the sentences\n",
    "- Use GPT3 to generate 5 abstract descriptions that describe each sentence in the subset, and 5 that do not\n",
    "- Then train an embedding model with contrastive loss so that that sentences have embeddings close to that of their corresponding descriptions.\n",
    "\n",
    "My questions\n",
    "- Can the notions of 'description', 'summary', 'paraphrase' be made more well-defined?\n",
    "- Is a suitable abstract description of an example dependent on what information we want to capture in the description? Or can we define the notion of description in a consistent way?\n",
    "- Was the evaluation sufficient?\n",
    "- How could I extend this? Apply it to my own research?\n",
    "- How to implement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "115618ce-a08a-422c-96de-8bc41c6e4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f814da-c737-4354-8507-e97c1d84f058",
   "metadata": {},
   "source": [
    "## Generating descriptions from sentences using ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2cd5163-7788-422b-95c2-a69e71148e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "api_key = os.environ.get(\"OPEN_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0dda773-870c-470f-9440-16b51794c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"My dad was very sad when Timmy the dog died. My parents buried him in the backyard with his favourite blanket.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f51c4ab9-6c0f-4322-b500-e561bc4f9170",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "You are a clear, observant writer who creates abstract descriptions from sentences.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36e01ff5-beef-45ee-b10d-efda800dddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt1 = f\"\"\"\n",
    "Let's write abstract descriptions of sentences. \n",
    "\n",
    "Example:\n",
    "Sentence: Pilate 's role in the events leading to the crucifixion lent themselves\n",
    "to melodrama , even tragedy , and Pilate often has a role in medieval mystery\n",
    "plays .\n",
    "\n",
    "Description: A description of a historical religious figure's involvement in a\n",
    "significant event and its later portrayal in art.\n",
    "\n",
    "Note: Descriptions can differ in the level of abstraction, granularity and the\n",
    "part of the sentence they focus on. Some descriptions neeed to be abstract, while\n",
    "others should be concrete and detailed.\n",
    "\n",
    "For the following sentence, write up 5 good and stand-alone, independent\n",
    "descriptions and 5 bad descriptions (which may be related, but are clearly wrong).\n",
    "Output a json file with keys 'good', 'bad'.\n",
    "\n",
    "Sentence: {sentence}\n",
    "\n",
    "Start your answer with a curly bracket.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3627a83-3938-46e1-b819-194f86f1c73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt1}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b63f3d4-f8d2-4a21-92c5-6e4fec5a3fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"good\": [\n",
      "\"A narrative depicting a personal experience of a family’s sorrow in the wake of a pet’s death.\", \n",
      "\"A reflection on a father's emotional response to the loss of a beloved family dog.\",\n",
      "\"A recollection that describes the end of a treasured pet's life and its burial in the family home.\",\n",
      "\"A story of grief encapsulated within the death of a pet and expressing concern for a parent's well-being.\",\n",
      "\"An account describing a somber familial event involving a dog's life and its sentimental burial.\"\n",
      "\n",
      "],\n",
      "\"bad\": [\n",
      "\"A jovial story recounting a memorable family vacation.\", \n",
      "\"An analysis of the economical impact of pet deaths.\",\n",
      "\"A description of a dad's excitement about a dog's playful antics.\", \n",
      "\"Depiction of a dog’s excitement after being rescued by a caring family.\", \n",
      "\"A recounting of how enthusiastically a father built a dog house in the backyard.\"\n",
      "]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bde8fe5-7dda-4aee-9618-7a6d11dd89e6",
   "metadata": {},
   "source": [
    "## Hugginface model\n",
    "\n",
    "Need two models: the sentence encoder and the query encoder\n",
    "\n",
    "- https://huggingface.co/biu-nlp/abstract-sim-sentence\n",
    "- https://huggingface.co/biu-nlp/abstract-sim-query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3156ef5-8112-49fe-8c89-4b7d2f9512cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from typing import List\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b18b5ce0-0022-421f-8fa8-491382ab78f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_finetuned_model():\n",
    "    sentence_encoder = AutoModel.from_pretrained(\"biu-nlp/abstract-sim-sentence\") # load the sentence encoder\n",
    "    query_encoder = AutoModel.from_pretrained(\"biu-nlp/abstract-sim-query\") # load the query encoder\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"biu-nlp/abstract-sim-sentence\") # tokenizer (converts the text to tokens)\n",
    "    return tokenizer, query_encoder, sentence_encoder\n",
    "\n",
    "def encode_batch(model, tokenizer, sentences: List[str], device: str):\n",
    "    \"\"\"\n",
    "    Given a model, a tokenizer and a list of strings representing sentences return the text features\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    model: hf model\n",
    "    tokenizer: hf tokenizer\n",
    "    sentences: list of strings representing the sentences to be encoded\n",
    "    device: cpu or gpu (?)\n",
    "    \"\"\"\n",
    "    input_ids = tokenizer(sentences, \n",
    "                          padding=True, \n",
    "                          max_length=512, \n",
    "                          truncation=True, \n",
    "                          return_tensors=\"pt\",\n",
    "                          add_special_tokens=True).to(device)\n",
    "    features = model(**input_ids)[0]\n",
    "    features =  torch.sum(features[:,1:,:] * input_ids[\"attention_mask\"][:,1:].unsqueeze(-1), dim=1) / torch.clamp(torch.sum(input_ids[\"attention_mask\"][:,1:], dim=1, keepdims=True), min=1e-9)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8c5038e-1de3-4491-85e5-eae43a7b84bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexlee/Desktop/Coding/hf_testing/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load the tokenizer, query encoder and the sentence encoder\n",
    "tokenizer, query_encoder, sentence_encoder = load_finetuned_model()\n",
    "\n",
    "# examples of relevant sentences that should be returned given the query below\n",
    "relevant_sentences = [\"Fingersoft's parent company is the Finger Group.\",\n",
    "                      \"WHIRC – a subsidiary company of Wright-Hennepin\",\n",
    "                      \"CK Life Sciences International (Holdings) Inc. (), or CK Life Sciences, is a subsidiary of CK Hutchison Holdings\",\n",
    "                      \"EM Microelectronic-Marin (subsidiary of The Swatch Group).\",\n",
    "                      \"The company is currently a division of the corporate group Jam Industries.\",\n",
    "                      \"Volt Technical Resources is a business unit of Volt Workforce Solutions, a subsidiary of Volt Information Sciences (currently trading over-the-counter as VISI.).\"\n",
    "                     ]\n",
    "\n",
    "# examples of irrelevant sentences that should not be returned\n",
    "irrelevant_sentences = [\"The second company is deemed to be a subsidiary of the parent company.\",\n",
    "                        \"The company has gone through more than one incarnation.\",\n",
    "                        \"The company is owned by its employees.\",\n",
    "                        \"Larger companies compete for market share by acquiring smaller companies that may own a particular market sector.\",\n",
    "                        \"A parent company is a company that owns 51% or more voting stock in another firm (or subsidiary).\",\n",
    "                        \"It is a holding company that provides services through its subsidiaries in the following areas: oil and gas, industrial and infrastructure, government and power.\",\n",
    "                        \"RXVT Technologies is no longer a subsidiary of the parent company.\"\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2bddcb8-1fb4-49fe-a318-0b80303307ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = relevant_sentences + irrelevant_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aecff78a-65d1-4cf3-bc59-0b358a6898b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"<query>: An misunderstanding that could have resulted in someone getting into trouble\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87aabac2-b0db-440a-852f-7f18b66d6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy array representing the embeddings of each of the sentences\n",
    "embeddings = encode_batch(sentence_encoder, tokenizer, all_sentences, \"cpu\").detach().cpu().numpy()\n",
    "\n",
    "# numpy array representing the embedding of the query\n",
    "query_embedding = encode_batch(query_encoder, tokenizer, [query], \"cpu\").detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c24a9f96-d7f9-4b10-975c-4a56bcafb671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b15a9cd9-c110-43e8-ae4b-b34536015280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48d16f93-3395-40a5-a0e9-257bb2ce289f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHIRC – a subsidiary company of Wright-Hennepin 0.9396287\n",
      "EM Microelectronic-Marin (subsidiary of The Swatch Group). 0.93929076\n",
      "Fingersoft's parent company is the Finger Group. 0.9362471\n",
      "CK Life Sciences International (Holdings) Inc. (), or CK Life Sciences, is a subsidiary of CK Hutchison Holdings 0.9350311\n",
      "The company is currently a division of the corporate group Jam Industries. 0.927349\n",
      "Volt Technical Resources is a business unit of Volt Workforce Solutions, a subsidiary of Volt Information Sciences (currently trading over-the-counter as VISI.). 0.90050864\n",
      "The second company is deemed to be a subsidiary of the parent company. 0.6723647\n",
      "It is a holding company that provides services through its subsidiaries in the following areas: oil and gas, industrial and infrastructure, government and power. 0.60081375\n",
      "A parent company is a company that owns 51% or more voting stock in another firm (or subsidiary). 0.5949048\n",
      "The company is owned by its employees. 0.55286556\n",
      "RXVT Technologies is no longer a subsidiary of the parent company. 0.43219543\n",
      "The company has gone through more than one incarnation. 0.38889498\n",
      "Larger companies compete for market share by acquiring smaller companies that may own a particular market sector. 0.25472647\n"
     ]
    }
   ],
   "source": [
    "# calculate the cosine similarities between the query embedding and all other embeddings\n",
    "sims = cosine_similarity(query_embedding, embeddings)[0]\n",
    "\n",
    "# all sentences along with similarity score with the query\n",
    "sentences_sims = list(zip(all_sentences, sims))\n",
    "sentences_sims.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for s, sim in sentences_sims:\n",
    "    print(s, sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514b6497-ad9b-4384-b7bc-1ebfa548b521",
   "metadata": {},
   "source": [
    "## Application: search through Hansard petitions for weird things\n",
    "\n",
    "https://www.aph.gov.au/Parliamentary_Business/Hansard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23aacb68-1220-4d8a-adaa-4ff43a06abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from typing import List\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cafe1a6-db5d-483e-b504-e6ca793f64b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n"
     ]
    }
   ],
   "source": [
    "# load a hansard document\n",
    "reader = PdfReader(\"/Users/alexlee/Desktop/Data/pdfs/House of Representatives_2024_06_03.pdf\")\n",
    "number_of_pages = len(reader.pages)\n",
    "print(number_of_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ac4cf28-ec34-4e3a-b174-7a58bff83b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = ''\n",
    "\n",
    "for page in reader.pages[19:]:\n",
    "    text = page.extract_text()\n",
    "    all_text += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f42348f8-0f6e-4912-8930-453aea5e8804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/alexlee/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the Punkt tokenizer for sentence splitting\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eceb731a-068e-44ae-ad74-84bf19b7edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove introductory pages\n",
    "texts_tidier = all_text[113:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e51af4-20a7-4dc6-a507-ba6392a2ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_tidier = (\n",
    "    texts_tidier\n",
    "    .replace('\\n', ' ')\n",
    "    .replace('\\n- ', '. ')\n",
    "    .replace('\\n* ', '. ')\n",
    "    .replace('\\n1. ', '. ')\n",
    "    .replace('•', '. ')\n",
    "    .replace(':', '. ')\n",
    "    .replace(';', '. ')\n",
    "    .replace('.', '. ')\n",
    "    .replace('?', '. ')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af1635e4-0bd1-4b91-a1f4-681e0d2c381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(texts_tidier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fda9799d-3f25-4e14-919f-d3852f6cb09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_finetuned_model():\n",
    "    sentence_encoder = AutoModel.from_pretrained(\"biu-nlp/abstract-sim-sentence\") # load the sentence encoder\n",
    "    query_encoder = AutoModel.from_pretrained(\"biu-nlp/abstract-sim-query\") # load the query encoder\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"biu-nlp/abstract-sim-sentence\") # tokenizer (converts the text to tokens)\n",
    "    return tokenizer, query_encoder, sentence_encoder\n",
    "\n",
    "def encode_batch(model, tokenizer, sentences: List[str], device: str):\n",
    "    \"\"\"\n",
    "    Given a model, a tokenizer and a list of strings representing sentences return the text features\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    model: hf model\n",
    "    tokenizer: hf tokenizer\n",
    "    sentences: list of strings representing the sentences to be encoded\n",
    "    device: cpu or gpu (?)\n",
    "    \"\"\"\n",
    "    input_ids = tokenizer(sentences, \n",
    "                          padding=True, \n",
    "                          max_length=512, \n",
    "                          truncation=True, \n",
    "                          return_tensors=\"pt\",\n",
    "                          add_special_tokens=True).to(device)\n",
    "    features = model(**input_ids)[0]\n",
    "    features =  torch.sum(features[:,1:,:] * input_ids[\"attention_mask\"][:,1:].unsqueeze(-1), dim=1) / torch.clamp(torch.sum(input_ids[\"attention_mask\"][:,1:], dim=1, keepdims=True), min=1e-9)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "085987d9-6779-44b0-8afc-a433100eed8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexlee/Desktop/Coding/hf_testing/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# create the embeddings\n",
    "# load the tokenizer, query encoder and the sentence encoder\n",
    "tokenizer, query_encoder, sentence_encoder = load_finetuned_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa6c056a-88ad-42e6-a24b-cbcf47052a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings = encode_batch(sentence_encoder, tokenizer, sentences[:5], \"cpu\").detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dea19e6-8a1e-4596-b0f2-0bcbcb8ec429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c07489f-ae15-4864-8162-6109c666f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy array representing the embedding of the query\n",
    "query = \"<query>: A group of people overcoming a significant challenge\"\n",
    "query_embedding = encode_batch(query_encoder, tokenizer, [query], \"cpu\").detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1bde989-83fe-4004-ab33-ecf9fd9f6ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current rental crises is hard enough, stop landlords and agents from taking advantage of the situation 0.0631634\n",
      "When does it stop? The government needs to step in and put regulations in place to stop this and even reduce what has already happened 0.027913576\n",
      "Put a limit on how much of an increase is allowed and a time limit -0.073042616\n",
      "Presentation Ms TEMPLEMAN (Macquarie) (10:01):  I present the following 54 petitions: Housing Rental price increases are putting Australians on the street, in cars, tents, couches and under bridges -0.08194008\n",
      "We therefore ask the House to regulate the housing rental increases -0.13467577\n"
     ]
    }
   ],
   "source": [
    "# calculate the cosine similarities between the query embedding and all other embeddings\n",
    "sims = cosine_similarity(query_embedding, embeddings)[0]\n",
    "\n",
    "# all sentences along with similarity score with the query\n",
    "sentences_sims = list(zip(sentences, sims))\n",
    "sentences_sims.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for s, sim in sentences_sims:\n",
    "    print(s, sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71cce9eb-fa42-4ddc-97fc-97f2580a740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a01e7aaf-ff3c-4911-9d22-0f72bcd3f204",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chunks = len(sentences) // 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc2dcf91-0f92-4a14-a07d-440056c0c599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d69f894-5c94-44f0-8b9b-a25f9109b228",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sentence_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa126472-dad3-4c63-ab78-1f9e1a079632",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = []\n",
    "\n",
    "# have to do in chunks and then still get a kernel dying if two chunks done consecutively. Why?\n",
    "# issue with the model creating the features\n",
    "for n in range(90, 96):\n",
    "    print(f'Creating features for chunk {n}')\n",
    "    input_ids = tokenizer(sentences[n*100:(n+1)*100], \n",
    "                          padding=True, \n",
    "                          max_length=512, \n",
    "                          truncation=True, \n",
    "                          return_tensors=\"pt\",\n",
    "                          add_special_tokens=True).to(device)\n",
    "    features = model(**input_ids)[0]\n",
    "    features =  torch.sum(features[:,1:,:] * input_ids[\"attention_mask\"][:,1:].unsqueeze(-1), dim=1) / torch.clamp(torch.sum(input_ids[\"attention_mask\"][:,1:], dim=1, keepdims=True), min=1e-9)\n",
    "    all_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fb0fc79-ba75-4eb0-b286-250ecfa96fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_final = torch.concatenate(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc617e22-caf7-467d-a789-d3a8ef1719bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the tensors\n",
    "tensor_files = [f'features_part{n}.pt' for n in range(0, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07541381-991f-41f3-a9c8-b8cf3e0b4b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tensors = torch.concatenate([torch.load(tensor_files[n]) for n in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3cb14315-8411-4930-bf80-f765c55b1422",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"<query>: Concerns about young people\"\n",
    "query_embedding = encode_batch(query_encoder, tokenizer, [query], \"cpu\").detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5276b469-0d48-441d-8e8e-e8bae60056dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = all_tensors.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ceb0e0-85ab-4084-a3ac-c136377c9a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = cosine_similarity(query_embedding, embeddings)[0]\n",
    "\n",
    "# all sentences along with similarity score with the query\n",
    "sentences_sims = list(zip(sentences, sims))\n",
    "sentences_sims.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for s, sim in sentences_sims:\n",
    "    print(s, sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
